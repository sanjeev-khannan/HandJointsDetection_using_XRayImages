# Hand Joints Prediction using X-Ray Images
The Hand Joint Detection project is dedicated to the precise localization of key joint positions in X-ray images of right hands. The dataset, comprising image files and corresponding hand annotations, undergoes meticulous preprocessing to exclude images lacking labels or featuring both hands or the left hand. Unlike traditional object detection approaches, this project employs traditional convolutional layers for feature extraction and fully connected layers for predicting 36 points of the hand in a regression task. The primary objective is to predict 36 values per image, including x and y coordinates and finger angles for 12 pivotal hand points. The utilization of X-ray images enhances the model's capability to discern intricate details. This Deep Learning project strives to provide hand joint predictions, offering valuable assistance in medical diagnostics and treatment planning for conditions affecting hand structures.
